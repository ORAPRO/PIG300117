--WordCount

rm -r /home/edureka/SAIWS/Dataset/PIG/WordCount/

lines = LOAD '/home/edureka/WordCount.txt' USING TextLoader AS (line:chararray);
words = FOREACH lines GENERATE FLATTEN(TOKENIZE(line)) as word;
grouped = GROUP words BY word;
wordcount = FOREACH grouped GENERATE group, COUNT(words);
STORE wordcount INTO '/home/edureka/SAIWS/Dataset/PIG/WordCount/';


rm -r /home/edureka/SAIWS/Dataset/PIG/TEMPSTORAGE


V = LOAD '/home/edureka/SAIWS/Dataset/PIG/Visits.csv' USING PigStorage(',') AS (user:chararray,url:chararray,timestamp:chararray);
P = LOAD '/home/edureka/SAIWS/Dataset/PIG/Pages.csv' USING PigStorage(',') AS (url:chararray,prnk:float);                         
J = JOIN V by url,P by url;                                                                       
F = Filter J by P::prnk > 0.5; 
G = FOREACH F generate V::user, P::prnk;
D = DISTINCT G;
STORE D INTO '/home/edureka/SAIWS/Dataset/PIG/TEMPSTORAGE' ;           



M = LOAD '/home/edureka/SAIWS/Dataset/PIG/MapData.txt' USING PigStorage(',') AS (a:map[chararray],b:map[int]);
F = FOREACH M generate a#'NAME', b#'AGE';                                     
DUMP F;


S = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/student' AS (name:chararray,age:int,gpa:float);
G = GROUP S by name;
SR = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/studentRoll' AS (name:chararray,rollno:int);
CO = COGROUP S by name, SR by name;
J = JOIN S by name, SR by name;


--JOIN

D = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/data1' AS (a:int,b:int);
S = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/data2' AS (c:int,d:int);
J = JOIN D by a, S by c;
DUMP J;

--UNION
A = load '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/data1' as (a1:int, a2:int);
B = load '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/data2' as (b1:int, b2:int);
X = UNION A, B;


--REPLICATED, SKEWED JOIN
C = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/custs' USING PigStorage(',');
T = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/txns' USING PigStorage(','); 
J = JOIN T by $2 ,C by $0 USING 'replicated';
L = LIMIT J 100;
DUMP L;

--skewed
C = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/custs' USING PigStorage(',');
T = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/txns' USING PigStorage(','); 
J = JOIN C by $0, T by $2 USING 'skewed';
L = LIMIT J 100;
DUMP L;

--MERGE JOIN IN MAPRED
C = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/custs' USING PigStorage(',');
T = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/txns' USING PigStorage(','); 
CS = ORDER C by $0 ASC;
TS = ORDER T by $2 ASC;
J = JOIN CS by $0, TS by $2 USING 'merge';
L = LIMIT J 100;
DUMP L;

--- STREAM OPERATOR

T = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/txns' USING PigStorage(',');
top10 = STREAM T THROUGH `head -n 10`;
DUMP top10;


Parameters

cd /home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase

pig -x local -param DATA=healthcare_Sample_dataset1.csv myparams.pig

executing using file

pig -x local -param_file params myparams.pig

----PIGGY BANK

REGISTER /usr/lib/pig-0.12.0/contrib/piggybank/java/piggybank.jar;
L = LOAD '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Lower.txt' USING PigStorage(',');
B = FOREACH L GENERATE org.apache.pig.piggybank.evaluation.string.UPPER($0),$1;
DUMP B;


--Describe Explain illustrate


V = LOAD '/home/edureka/SAIWS/Dataset/PIG/Visits.csv' USING PigStorage(',') AS (user:chararray,url:chararray,timestamp:chararray);
P = LOAD '/home/edureka/SAIWS/Dataset/PIG/Pages.csv' USING PigStorage(',') AS (url:chararray,prnk:float);                         
J = JOIN V by url,P by url;                                                                       
F = Filter J by P::prnk > 0.5; 
DESCRIBE F;
EXPLAIN F;
ILLUSTRATE F;



----loading and parsing data-----
rm -r /home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/data6

rm -r /home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/data6

A = load '/home/edureka/SAIWS/Dataset/PIG/weatherExampleInPig/weatherPIG.txt' using TextLoader as (data:chararray);
AF = foreach A generate TRIM(SUBSTRING(data, 6, 14)), TRIM(SUBSTRING(data, 46, 53)), TRIM(SUBSTRING(data, 38, 45));
store AF into '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/data6' using PigStorage(',');
S  = load '/home/edureka/SAIWS/Dataset/PIG/Class_4_Usecase/Pig_Scripts_datasets/data6/' using PigStorage(',') as (date:chararray, min:double, max:double);

-------Hot Days------

X = filter S by max > 25;
dump X;

-------Cold Days------

X = filter S by min < 0;
dump X;

-------Hottest Day-----

/* puts S's data in H1's Tuple */

H1 = group S all; 	
I = foreach H1 generate MAX(S.max) as maximum;
X = filter S by max == I.maximum;

-------Coldest Day------

H2 = group S all;
J = foreach H2 generate MIN(S.min) as minimum;
X = filter S by min == J.minimum;


-----UDF-----
register PIGUdfCorrupt.jar;

A = load '/weatherPIG' using TextLoader as (data:chararray);
AF = foreach A generate TRIM(SUBSTRING(data, 6, 14)), IfCorrupted(TRIM(SUBSTRING(data, 46, 53))), IfCorrupted(TRIM(SUBSTRING(data, 38, 45)));
store AF into '/data2' using PigStorage(',');
S = load '/data2/part-m-00000' using PigStorage(',') as (date:chararray, min:double, max:double);


------------------

A = load '/data1' as (a1:int, a2:int);
B = load '/data2' as (b1:int, b2:int);
X = UNION A, B;
dump X;
//onschema


----------------------------------

A = LOAD '/j1' as (a1:int, a2:int, a3:int);
B = LOAD '/j2' as (b1:int, b2:int);
X = JOIN A BY a1, B BY b1;
dump X;

------------------------------------

A = load '/student' as (name:chararray, age:int, gpa:float);
B = load '/studentRoll' as (name:chararray, rollno:int);

X = group A by name;
dump X;

X = cogroup Aby name, B by name;
dump X;

register myudf.jar;
X = filter A by IsOfAge(age);

